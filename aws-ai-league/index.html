<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><meta name="generator" content="Gatsby 5.15.0"/><meta name="theme-color" content="#663399"/><meta data-react-helmet="true" name="description" content="I promised a lot of folks I’d write a blog if I won the AWS AI League, so here I am writing this after finishing 2nd.  Before we begin, here’s a little brief…"/><meta data-react-helmet="true" property="og:title" content="Building, Breaking, and Tuning - My Experience at the AWS AI League | The Curious Engineer"/><meta data-react-helmet="true" property="og:description" content="I promised a lot of folks I’d write a blog if I won the AWS AI League, so here I am writing this after finishing 2nd.  Before we begin, here’s a little brief…"/><meta data-react-helmet="true" property="og:type" content="website"/><meta data-react-helmet="true" name="twitter:card" content="summary"/><meta data-react-helmet="true" name="twitter:creator" content="_nobodyme_"/><meta data-react-helmet="true" name="twitter:title" content="Building, Breaking, and Tuning - My Experience at the AWS AI League | The Curious Engineer"/><meta data-react-helmet="true" name="twitter:description" content="I promised a lot of folks I’d write a blog if I won the AWS AI League, so here I am writing this after finishing 2nd.  Before we begin, here’s a little brief…"/><style data-href="/blog/styles.de78337784b71bd04610.css" data-identity="gatsby-global-css">@font-face{font-display:swap;font-family:MontserratVariable;font-style:normal;font-weight:100 900;src:url(/blog/static/montserrat-cyrillic-variable-wghtOnly-normal-f41a9bc7688bda1e84508030cb5c18fe.woff2) format("woff2");unicode-range:u+0301,u+0400-045f,u+0490-0491,u+04b0-04b1,u+2116}@font-face{font-display:swap;font-family:MontserratVariable;font-style:normal;font-weight:100 900;src:url(/blog/static/montserrat-cyrillic-ext-variable-wghtOnly-normal-639b3c91831427d83cd3984af014778c.woff2) format("woff2");unicode-range:u+0460-052f,u+1c80-1c88,u+20b4,u+2de0-2dff,u+a640-a69f,u+fe2e-fe2f}@font-face{font-display:swap;font-family:MontserratVariable;font-style:normal;font-weight:100 900;src:url(/blog/static/montserrat-latin-variable-wghtOnly-normal-b66f2d18f66f15c3ac56a2f4d68b3be5.woff2) format("woff2");unicode-range:u+00??,u+0131,u+0152-0153,u+02bb-02bc,u+02c6,u+02da,u+02dc,u+2000-206f,u+2074,u+20ac,u+2122,u+2191,u+2193,u+2212,u+2215,u+feff,u+fffd}@font-face{font-display:swap;font-family:MontserratVariable;font-style:normal;font-weight:100 900;src:url(/blog/static/montserrat-latin-ext-variable-wghtOnly-normal-9f73369162c4382215d4317ba362fe1e.woff2) format("woff2");unicode-range:u+0100-024f,u+0259,u+1e??,u+2020,u+20a0-20ab,u+20ad-20cf,u+2113,u+2c60-2c7f,u+a720-a7ff}@font-face{font-display:swap;font-family:MontserratVariable;font-style:normal;font-weight:100 900;src:url(data:font/woff2;base64,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) format("woff2");unicode-range:u+0102-0103,u+0110-0111,u+0128-0129,u+0168-0169,u+01a0-01a1,u+01af-01b0,u+1ea0-1ef9,u+20ab}@font-face{font-display:swap;font-family:Merriweather;font-style:normal;font-weight:400;src:url(/blog/static/merriweather-cyrillic-ext-400-normal-2a880e22b1b888ab54652a36d43b7f16.woff2) format("woff2"),url(/blog/static/merriweather-all-400-normal-5e7a0e6a9b864b89292d60ba5da59d4b.woff) format("woff");unicode-range:u+0460-052f,u+1c80-1c88,u+20b4,u+2de0-2dff,u+a640-a69f,u+fe2e-fe2f}@font-face{font-display:swap;font-family:Merriweather;font-style:normal;font-weight:400;src:url(/blog/static/merriweather-cyrillic-400-normal-fde0b55efc50742fb57fbebbb11c572f.woff2) format("woff2"),url(/blog/static/merriweather-all-400-normal-5e7a0e6a9b864b89292d60ba5da59d4b.woff) format("woff");unicode-range:u+0301,u+0400-045f,u+0490-0491,u+04b0-04b1,u+2116}@font-face{font-display:swap;font-family:Merriweather;font-style:normal;font-weight:400;src:url(data:font/woff2;base64,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) format("woff2"),url(/blog/static/merriweather-all-400-normal-5e7a0e6a9b864b89292d60ba5da59d4b.woff) format("woff");unicode-range:u+0102-0103,u+0110-0111,u+0128-0129,u+0168-0169,u+01a0-01a1,u+01af-01b0,u+1ea0-1ef9,u+20ab}@font-face{font-display:swap;font-family:Merriweather;font-style:normal;font-weight:400;src:url(/blog/static/merriweather-latin-ext-400-normal-4657f5ab02d5923d223f96a9155a9bdc.woff2) format("woff2"),url(/blog/static/merriweather-all-400-normal-5e7a0e6a9b864b89292d60ba5da59d4b.woff) format("woff");unicode-range:u+0100-024f,u+0259,u+1e??,u+2020,u+20a0-20ab,u+20ad-20cf,u+2113,u+2c60-2c7f,u+a720-a7ff}@font-face{font-display:swap;font-family:Merriweather;font-style:normal;font-weight:400;src:url(/blog/static/merriweather-latin-400-normal-e009f21405b4d7e893674b69deb4cf4a.woff2) format("woff2"),url(/blog/static/merriweather-all-400-normal-5e7a0e6a9b864b89292d60ba5da59d4b.woff) format("woff");unicode-range:u+00??,u+0131,u+0152-0153,u+02bb-02bc,u+02c6,u+02da,u+02dc,u+2000-206f,u+2074,u+20ac,u+2122,u+2191,u+2193,u+2212,u+2215,u+feff,u+fffd}

/*! normalize.css v8.0.1 | MIT License | github.com/necolas/normalize.css */html{-webkit-text-size-adjust:100%;line-height:1.15}body{margin:0}main{display:block}h1{font-size:2em;margin:.67em 0}hr{box-sizing:content-box;height:0;overflow:visible}pre{font-family:monospace,monospace;font-size:1em}a{background-color:transparent}abbr[title]{border-bottom:none;text-decoration:underline;-webkit-text-decoration:underline dotted;text-decoration:underline dotted}b,strong{font-weight:bolder}code,kbd,samp{font-family:monospace,monospace;font-size:1em}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}img{border-style:none}button,input,optgroup,select,textarea{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]::-moz-focus-inner,[type=reset]::-moz-focus-inner,[type=submit]::-moz-focus-inner,button::-moz-focus-inner{border-style:none;padding:0}[type=button]:-moz-focusring,[type=reset]:-moz-focusring,[type=submit]:-moz-focusring,button:-moz-focusring{outline:1px dotted ButtonText}fieldset{padding:.35em .75em .625em}legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal}progress{vertical-align:baseline}textarea{overflow:auto}[type=checkbox],[type=radio]{box-sizing:border-box;padding:0}[type=number]::-webkit-inner-spin-button,[type=number]::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}details{display:block}summary{display:list-item}[hidden]{display:none}:root{--maxWidth-none:"none";--maxWidth-xs:20rem;--maxWidth-sm:24rem;--maxWidth-md:28rem;--maxWidth-lg:32rem;--maxWidth-xl:36rem;--maxWidth-2xl:42rem;--maxWidth-3xl:48rem;--maxWidth-4xl:56rem;--maxWidth-full:"100%";--maxWidth-wrapper:var(--maxWidth-2xl);--spacing-px:"1px";--spacing-0:0;--spacing-1:0.25rem;--spacing-2:0.5rem;--spacing-3:0.75rem;--spacing-4:1rem;--spacing-5:1.25rem;--spacing-6:1.5rem;--spacing-8:2rem;--spacing-10:2.5rem;--spacing-12:3rem;--spacing-16:4rem;--spacing-20:5rem;--spacing-24:6rem;--spacing-32:8rem;--fontFamily-sans:"Inter UI",sans-serif;--fontFamily-serif:-apple-system,BlinkMacSystemFont,"Segoe UI",Helvetica,Arial,sans-serif;--font-body:var(--fontFamily-serif);--font-heading:var(--fontFamily-sans);--fontWeight-normal:400;--fontWeight-medium:500;--fontWeight-semibold:600;--fontWeight-bold:700;--fontWeight-extrabold:800;--fontWeight-black:900;--fontSize-root:16px;--lineHeight-none:1;--lineHeight-tight:1.1;--lineHeight-normal:1.5;--lineHeight-relaxed:1.625;--fontSize-0:0.833rem;--fontSize-1:1rem;--fontSize-2:1.2rem;--fontSize-3:1.44rem;--fontSize-4:1.728rem;--fontSize-5:2.074rem;--fontSize-6:2.488rem;--fontSize-7:2.986rem;--color-primary:#24292e;--color-link:#0366d6;--color-text:#2e353f;--color-text-light:#4f5969;--color-text-lighter:#959da5;--color-heading:#1a202c;--color-accent:#d1dce5;--color-background-secondary:#f6f8fa;--red-50:#fef2f2;--red-200:#fecaca;--blue-50:#eff6ff;--blue-200:#bfdbfe;--color-inline-code:rgba(27,31,35,.05)}*,:after,:before{box-sizing:border-box}html{-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;font-size:var(--fontSize-root);line-height:var(--lineHeight-normal)}body{color:var(--color-primary);font-family:var(--font-body);font-size:var(--fontSize-1)}footer{padding:var(--spacing-6) var(--spacing-0)}hr{background:var(--color-accent);border:0;height:1px}h1,h2,h3,h4,h5,h6{font-family:var(--font-heading);letter-spacing:-.025em;line-height:var(--lineHeight-tight);margin-bottom:var(--spacing-6);margin-top:var(--spacing-12)}h2,h3,h4,h5,h6{color:var(--color-heading);font-weight:var(--fontWeight-bold)}h1{color:var(--color-primary);font-size:var(--fontSize-6);font-weight:var(--fontWeight-black)}h2{font-size:var(--fontSize-5)}h3{font-size:var(--fontSize-4)}h4{font-size:var(--fontSize-3)}h5{font-size:var(--fontSize-2)}h6{font-size:var(--fontSize-1)}h1>a,h2>a,h3>a,h4>a,h5>a,h6>a{color:inherit;text-decoration:none}p{--baseline-multiplier:0.179;--x-height-multiplier:0.35;line-height:var(--lineHeight-relaxed);margin:var(--spacing-0) var(--spacing-0) var(--spacing-8) var(--spacing-0)}ol,p,ul{padding:var(--spacing-0)}ol,ul{list-style-image:none;list-style-position:outside;margin-bottom:var(--spacing-8);margin-left:var(--spacing-0);margin-right:var(--spacing-0)}ol li,ul li{padding-left:var(--spacing-0)}li>p,ol li,ul li{margin-bottom:calc(var(--spacing-8)/2)}li :last-child{margin-bottom:var(--spacing-0)}li>ul{margin-left:var(--spacing-8);margin-top:calc(var(--spacing-8)/2)}blockquote{border-left:var(--spacing-1) solid var(--color-primary);color:var(--color-text-light);font-size:var(--fontSize-2);font-style:italic;margin-bottom:var(--spacing-8);margin-left:calc(var(--spacing-6)*-1);margin-right:var(--spacing-8);padding:var(--spacing-0) var(--spacing-0) var(--spacing-0) var(--spacing-6)}blockquote>:last-child{margin-bottom:var(--spacing-0)}blockquote>ol,blockquote>ul{list-style-position:inside}table{border-collapse:collapse;border-spacing:.25rem;margin-bottom:var(--spacing-8);width:100%}table thead tr th{border-bottom:1px solid var(--color-accent)}a{color:var(--color-link);text-decoration:none}a:focus,a:hover{text-decoration:underline}.global-header{justify-content:space-between;margin:var(--spacing-2) var(--spacing-20) var(--spacing-8)}.global-header,.header-title{align-items:center;display:flex}.header-title{font-family:var(--font-heading);justify-content:center}.header-title,.header-title:hover{text-decoration:none}.header-icon{margin-bottom:var(--spacing-0);margin-right:var(--spacing-4);position:relative;top:10px}.header-social{align-items:center;display:flex;justify-content:space-between}.header-social-link{margin-bottom:var(--spacing-0);margin-right:var(--spacing-4);position:relative;top:16px}.global-content-wrapper{margin:var(--spacing-0) auto;max-width:var(--maxWidth-wrapper);padding:var(--spacing-10) var(--spacing-5)}.post-list{list-style:none}.post-list:first-child{margin-top:0}.post-list-item{margin-bottom:var(--spacing-10)}.post-list-item h2,.post-list-item p{margin-bottom:var(--spacing-0)}.post-list-item h2{color:var(--color-primary);font-size:var(--fontSize-3);margin-top:var(--spacing-0)}.post-list-item header{margin-bottom:var(--spacing-4)}.post-list-item header span{line-height:var(--lineHeight-normal)}.post-list-item header span:focus,.post-list-item header span:hover{color:var(--color-link);text-decoration:underline}.blog-post header h1{margin:var(--spacing-0) var(--spacing-0) var(--spacing-4) var(--spacing-0)}.blog-post header p{font-family:var(--font-heading);font-size:var(--fontSize-2)}.blog-post-nav ul{margin:var(--spacing-0)}.gatsby-highlight{margin-bottom:var(--spacing-8)}.gatsby-highlight pre[class*=language-]{background-color:var(--color-background-secondary)}.meta{color:var(--color-text-lighter);font-weight:var(--fontWeight-medium)}.meta-separator{margin:0 var(--spacing-2)}footer .meta{font-weight:var(--fontWeight-normal)}footer span{margin-left:var(--spacing-1)}.blog-content{text-shadow:0 0}.blog-content ul,ol{margin-bottom:1.25rem;margin-top:0;padding-left:1.25rem}.blog-content ol li,.blog-content ul li{margin-bottom:calc(var(--spacing-4)/2);padding-left:var(--spacing-0)}.blog-content p:has(+ol),.blog-content p:has(+ul){margin-bottom:.75rem}.blog-content p{margin:var(--spacing-0) var(--spacing-0) var(--spacing-4) var(--spacing-0)}.error-box{background:var(--red-50);border:1px solid var(--red-200);padding:20px}.info-box{background:var(--blue-50);border:1px solid var(--blue-200);padding:20px}.liked-page-header{color:var(--color-primary);color:var(--color-text-lighter);font-size:var(--fontSize-2);font-weight:var(--fontWeight-medium)}.liked-post{margin-top:var(--spacing-3)}.liked-post-item{align-items:top;display:flex;justify-content:left;margin-bottom:var(--spacing-10)}.liked-post-item-link:hover{text-decoration:none}.liked-post-item-link-text{color:var(--color-primary);font-size:var(--fontSize-2);font-weight:var(--fontWeight-medium)}.liked-post-item-reaction{margin-right:var(--spacing-4);position:relative;top:5px}.giscus,.giscus-frame{width:100%}.giscus-frame{border:none}.hr{margin-bottom:20px}.header-social-icon{fill:var(--color-heading);color:var(--color-heading)}@media (max-width:42rem){blockquote{margin-left:var(--spacing-0);padding:var(--spacing-0) var(--spacing-0) var(--spacing-0) var(--spacing-4)}ol,ul{list-style-position:inside}}@media (max-width:800px){.global-header{margin:var(--spacing-2) var(--spacing-10) var(--spacing-8)}}@media (max-width:700px){.global-header{flex-direction:column;justify-content:center;margin:var(--spacing-2) var(--spacing-5) var(--spacing-8)}.header-social-icon{fill:var(--color-text-lighter);color:var(--color-text-lighter)}}@media (max-width:400px){.header-title{align-items:center;flex-direction:column;justify-content:center}.header-text{margin-bottom:var(--spacing-1);margin-top:var(--spacing-8)}.header-icon{margin-right:var(--spacing-4);position:relative;top:20px}.header-social-icon{fill:var(--color-text-lighter);color:var(--color-text-lighter)}}code[class*=language-],pre[class*=language-]{word-wrap:normal;background:none;color:#000;font-family:Consolas,Monaco,Andale Mono,Ubuntu Mono,monospace;font-size:1em;-webkit-hyphens:none;hyphens:none;line-height:1.5;tab-size:4;text-align:left;text-shadow:0 1px #fff;white-space:pre;word-break:normal;word-spacing:normal}code[class*=language-] ::selection,code[class*=language-]::selection,pre[class*=language-] ::selection,pre[class*=language-]::selection{background:#b3d4fc;text-shadow:none}@media print{code[class*=language-],pre[class*=language-]{text-shadow:none}}pre[class*=language-]{margin:.5em 0;overflow:auto;padding:1em}:not(pre)>code[class*=language-],pre[class*=language-]{background:#f5f2f0}:not(pre)>code[class*=language-]{border-radius:.3em;padding:.1em;white-space:normal}.token.cdata,.token.comment,.token.doctype,.token.prolog{color:#708090}.token.punctuation{color:#999}.token.namespace{opacity:.7}.token.boolean,.token.constant,.token.deleted,.token.number,.token.property,.token.symbol,.token.tag{color:#905}.token.attr-name,.token.builtin,.token.char,.token.inserted,.token.selector,.token.string{color:#690}.language-css .token.string,.style .token.string,.token.entity,.token.operator,.token.url{background:hsla(0,0%,100%,.5);color:#9a6e3a}.token.atrule,.token.attr-value,.token.keyword{color:#07a}.token.class-name,.token.function{color:#dd4a68}.token.important,.token.regex,.token.variable{color:#e90}.token.bold,.token.important{font-weight:700}.token.italic{font-style:italic}.token.entity{cursor:help}</style><link rel="preconnect" href="https://www.googletagmanager.com"/><link rel="dns-prefetch" href="https://www.googletagmanager.com"/><style>.gatsby-image-wrapper{position:relative;overflow:hidden}.gatsby-image-wrapper picture.object-fit-polyfill{position:static!important}.gatsby-image-wrapper img{bottom:0;height:100%;left:0;margin:0;max-width:none;padding:0;position:absolute;right:0;top:0;width:100%;object-fit:cover}.gatsby-image-wrapper [data-main-image]{opacity:0;transform:translateZ(0);transition:opacity .25s linear;will-change:opacity}.gatsby-image-wrapper-constrained{display:inline-block;vertical-align:top}</style><noscript><style>.gatsby-image-wrapper noscript [data-main-image]{opacity:1!important}.gatsby-image-wrapper [data-placeholder-image]{opacity:0!important}</style></noscript><script type="module">const e="undefined"!=typeof HTMLImageElement&&"loading"in HTMLImageElement.prototype;e&&document.body.addEventListener("load",(function(e){const t=e.target;if(void 0===t.dataset.mainImage)return;if(void 0===t.dataset.gatsbyImageSsr)return;let a=null,n=t;for(;null===a&&n;)void 0!==n.parentNode.dataset.gatsbyImageWrapper&&(a=n.parentNode),n=n.parentNode;const o=a.querySelector("[data-placeholder-image]"),r=new Image;r.src=t.currentSrc,r.decode().catch((()=>{})).then((()=>{t.style.opacity=1,o&&(o.style.opacity=0,o.style.transition="opacity 500ms linear")}))}),!0);</script><link rel="alternate" type="application/rss+xml" title="The Curious Engineer" href="/blog/rss.xml"/><link rel="icon" href="/blog/favicon-32x32.png?v=c56c22e29aa7a6e9a5dc5fc560eb2796" type="image/png"/><link rel="manifest" href="/blog/manifest.webmanifest" crossorigin="anonymous"/><link rel="apple-touch-icon" sizes="48x48" href="/blog/icons/icon-48x48.png?v=c56c22e29aa7a6e9a5dc5fc560eb2796"/><link rel="apple-touch-icon" sizes="72x72" href="/blog/icons/icon-72x72.png?v=c56c22e29aa7a6e9a5dc5fc560eb2796"/><link rel="apple-touch-icon" sizes="96x96" href="/blog/icons/icon-96x96.png?v=c56c22e29aa7a6e9a5dc5fc560eb2796"/><link rel="apple-touch-icon" sizes="144x144" href="/blog/icons/icon-144x144.png?v=c56c22e29aa7a6e9a5dc5fc560eb2796"/><link rel="apple-touch-icon" sizes="192x192" href="/blog/icons/icon-192x192.png?v=c56c22e29aa7a6e9a5dc5fc560eb2796"/><link rel="apple-touch-icon" sizes="256x256" href="/blog/icons/icon-256x256.png?v=c56c22e29aa7a6e9a5dc5fc560eb2796"/><link rel="apple-touch-icon" sizes="384x384" href="/blog/icons/icon-384x384.png?v=c56c22e29aa7a6e9a5dc5fc560eb2796"/><link rel="apple-touch-icon" sizes="512x512" href="/blog/icons/icon-512x512.png?v=c56c22e29aa7a6e9a5dc5fc560eb2796"/><title data-react-helmet="true">Building, Breaking, and Tuning - My Experience at the AWS AI League | The Curious Engineer | The Curious Engineer</title></head><body><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><div><div class="global-header"><a class="header-title" href="/blog/"><svg class="header-icon" width="35" height="35" viewBox="0 0 80 80"><g id="surface54229706"><path style="stroke:none;fill-rule:nonzero;fill:rgb(0%,0%,0%);fill-opacity:1" d="M 49 25.664062 L 49 16 C 49 12.140625 52.140625 9 56 9 C 59.859375 9 63 12.140625 63 16 L 63 25.664062 Z M 49 25.664062 "></path><path style="stroke:none;fill-rule:nonzero;fill:rgb(0%,0%,0%);fill-opacity:1" d="M 56 10 C 59.308594 10 62 12.691406 62 16 L 62 24.664062 L 50 24.664062 L 50 16 C 50 12.691406 52.691406 10 56 10 M 56 8 C 51.582031 8 48 11.582031 48 16 C 48 16.457031 48 26.210938 48 26.664062 L 64 26.664062 C 64 26.210938 64 16.457031 64 16 C 64 11.582031 60.417969 8 56 8 Z M 56 8 "></path><path style="stroke:none;fill-rule:nonzero;fill:rgb(0%,0%,0%);fill-opacity:1" d="M 47 52.921875 L 47 25.6875 C 47 22.855469 49.589844 17 57.59375 17 C 64.875 17 68.335938 22.289062 68.371094 22.339844 C 68.414062 22.453125 78.285156 43.175781 78.964844 52.921875 Z M 47 52.921875 "></path><path style="stroke:none;fill-rule:nonzero;fill:rgb(0%,0%,0%);fill-opacity:1" d="M 57.59375 18 C 63.84375 18 67.007812 22.136719 67.472656 22.796875 C 68.28125 24.511719 76.683594 42.453125 77.863281 51.925781 L 48 51.925781 L 48 25.6875 C 48 23.695312 49.761719 18 57.59375 18 M 57.59375 16 C 48.640625 16 46 22.679688 46 25.6875 C 46 28.148438 46 36.449219 46 53.925781 L 80 53.925781 C 80 44.34375 69.210938 21.804688 69.210938 21.804688 C 69.210938 21.804688 65.507812 16 57.59375 16 Z M 57.59375 16 "></path><path style="stroke:none;fill-rule:nonzero;fill:rgb(0%,0%,0%);fill-opacity:1" d="M 33 28.09375 C 34.371094 27.730469 37.488281 27 40.242188 27 C 42.949219 27 45.746094 27.707031 47 28.070312 L 47 44.652344 C 45.503906 44.238281 42.929688 43.667969 40.242188 43.667969 C 37.472656 43.667969 34.609375 44.277344 33 44.6875 Z M 33 28.09375 "></path><path style="stroke:none;fill-rule:nonzero;fill:rgb(0%,0%,0%);fill-opacity:1" d="M 40.242188 28 C 42.394531 28 44.621094 28.476562 46 28.835938 L 46 43.371094 C 44.449219 43.015625 42.378906 42.664062 40.242188 42.664062 C 37.992188 42.664062 35.691406 43.050781 34 43.421875 L 34 28.871094 C 35.519531 28.503906 38.007812 28 40.242188 28 M 40.242188 26 C 36.40625 26 32 27.335938 32 27.335938 C 32 27.335938 32 31.582031 32 35.335938 C 32 36.28125 32 37.195312 32 38 C 32 40.300781 32 43.617188 32 46 C 32 46 36.269531 44.664062 40.242188 44.664062 C 44.214844 44.664062 48 46 48 46 C 48 43.617188 48 40.300781 48 38 C 48 37.195312 48 36.277344 48 35.335938 C 48 31.582031 48 27.335938 48 27.335938 C 48 27.335938 44.074219 26 40.242188 26 Z M 40.242188 26 "></path><path style="stroke:none;fill-rule:nonzero;fill:rgb(87.450981%,94.117647%,99.607843%);fill-opacity:1" d="M 63 39 C 54.164062 39 47 46.164062 47 55 C 47 63.835938 54.164062 71 63 71 C 71.835938 71 79 63.835938 79 55 C 79 46.164062 71.835938 39 63 39 Z M 63 39 "></path><path style="stroke:none;fill-rule:nonzero;fill:rgb(0%,0%,0%);fill-opacity:1" d="M 63 40 C 71.269531 40 78 46.726562 78 55 C 78 63.273438 71.269531 70 63 70 C 54.730469 70 48 63.273438 48 55 C 48 46.726562 54.730469 40 63 40 M 63 38 C 53.613281 38 46 45.613281 46 55 C 46 64.386719 53.613281 72 63 72 C 72.386719 72 80 64.386719 80 55 C 80 45.613281 72.386719 38 63 38 Z M 63 38 "></path><path style="fill:none;stroke-width:8.6;stroke-linecap:round;stroke-linejoin:miter;stroke:rgb(100%,100%,100%);stroke-opacity:1;stroke-miterlimit:10" d="M 120.4 120.4 C 120.4 110.901367 128.101367 103.2 137.6 103.2 " transform="matrix(0.465116,0,0,0.465116,0,0)"></path><path style="stroke:none;fill-rule:nonzero;fill:rgb(0%,0%,0%);fill-opacity:1" d="M 17 25.664062 L 17 16 C 17 12.140625 20.140625 9 24 9 C 27.859375 9 31 12.140625 31 16 L 31 25.664062 Z M 17 25.664062 "></path><path style="stroke:none;fill-rule:nonzero;fill:rgb(0%,0%,0%);fill-opacity:1" d="M 24 10 C 27.308594 10 30 12.691406 30 16 L 30 24.664062 L 18 24.664062 L 18 16 C 18 12.691406 20.691406 10 24 10 M 24 8 C 19.582031 8 16 11.582031 16 16 C 16 16.457031 16 26.210938 16 26.664062 L 32 26.664062 C 32 26.210938 32 16.457031 32 16 C 32 11.582031 28.417969 8 24 8 Z M 24 8 "></path><path style="stroke:none;fill-rule:nonzero;fill:rgb(0%,0%,0%);fill-opacity:1" d="M 1.039062 52.921875 C 1.71875 43.171875 11.585938 22.449219 11.691406 22.234375 C 11.769531 22.125 15.171875 17 22.40625 17 C 30.410156 17 33 22.851562 33 25.6875 L 33 52.925781 L 1.039062 52.925781 Z M 1.039062 52.921875 "></path><path style="stroke:none;fill-rule:nonzero;fill:rgb(0%,0%,0%);fill-opacity:1" d="M 22.40625 18 C 30.238281 18 32 23.695312 32 25.6875 L 32 51.925781 L 2.136719 51.925781 C 3.316406 42.453125 11.71875 24.511719 12.53125 22.796875 C 12.980469 22.152344 16.15625 18 22.40625 18 M 22.40625 16 C 14.492188 16 10.785156 21.804688 10.785156 21.804688 C 10.785156 21.804688 0 44.34375 0 53.925781 L 34 53.925781 C 34 36.453125 34 28.148438 34 25.6875 C 34 22.679688 31.359375 16 22.40625 16 Z M 22.40625 16 "></path><path style="stroke:none;fill-rule:nonzero;fill:rgb(87.450981%,94.117647%,99.607843%);fill-opacity:1" d="M 17 39 C 8.164062 39 1 46.164062 1 55 C 1 63.835938 8.164062 71 17 71 C 25.835938 71 33 63.835938 33 55 C 33 46.164062 25.835938 39 17 39 Z M 17 39 "></path><path style="stroke:none;fill-rule:nonzero;fill:rgb(0%,0%,0%);fill-opacity:1" d="M 17 40 C 25.269531 40 32 46.726562 32 55 C 32 63.273438 25.269531 70 17 70 C 8.730469 70 2 63.273438 2 55 C 2 46.726562 8.730469 40 17 40 M 17 38 C 7.613281 38 0 45.613281 0 55 C 0 64.386719 7.613281 72 17 72 C 26.386719 72 34 64.386719 34 55 C 34 45.613281 26.386719 38 17 38 Z M 17 38 "></path><path style="fill:none;stroke-width:8.6;stroke-linecap:round;stroke-linejoin:miter;stroke:rgb(100%,100%,100%);stroke-opacity:1;stroke-miterlimit:10" d="M 21.5 120.4 C 21.5 110.901367 29.201367 103.2 38.7 103.2 " transform="matrix(0.465116,0,0,0.465116,0,0)"></path></g></svg><h3 class="header-text">The Curious Engineer</h3></a><div class="header-social"><a class="header-social-link" href="/blog/liked-posts/"><svg class="header-social-icon" width="35" height="35" viewBox="0 0 24 24"><path d="M19.3 5.71002C18.841 5.24601 18.2943 4.87797 17.6917 4.62731C17.0891 4.37666 16.4426 4.2484 15.79 4.25002C15.1373 4.2484 14.4909 4.37666 13.8883 4.62731C13.2857 4.87797 12.739 5.24601 12.28 5.71002L12 6.00002L11.72 5.72001C10.7917 4.79182 9.53273 4.27037 8.22 4.27037C6.90726 4.27037 5.64829 4.79182 4.72 5.72001C3.80386 6.65466 3.29071 7.91125 3.29071 9.22002C3.29071 10.5288 3.80386 11.7854 4.72 12.72L11.49 19.51C11.6306 19.6505 11.8212 19.7294 12.02 19.7294C12.2187 19.7294 12.4094 19.6505 12.55 19.51L19.32 12.72C20.2365 11.7823 20.7479 10.5221 20.7442 9.21092C20.7405 7.89973 20.2218 6.64248 19.3 5.71002Z" fill="currentColor"></path></svg></a><a class="header-social-link" href="https://www.linkedin.com/in/naveen-kumar-b11464128/" target="_blank" rel="noopener noreferrer"><svg class="header-social-icon" width="30" height="30" fill="#1A1A1A" viewBox="0 0 50 50"><path d="M41,4H9C6.24,4,4,6.24,4,9v32c0,2.76,2.24,5,5,5h32c2.76,0,5-2.24,5-5V9C46,6.24,43.76,4,41,4z M17,20v19h-6V20H17z M11,14.47c0-1.4,1.2-2.47,3-2.47s2.93,1.07,3,2.47c0,1.4-1.12,2.53-3,2.53C12.2,17,11,15.87,11,14.47z M39,39h-6c0,0,0-9.26,0-10 c0-2-1-4-3.5-4.04h-0.08C27,24.96,26,27.02,26,29c0,0.91,0,10,0,10h-6V20h6v2.56c0,0,1.93-2.56,5.81-2.56 c3.97,0,7.19,2.73,7.19,8.26V39z"></path></svg></a><a class="header-social-link" href="https://github.com/nobodyme" target="_blank" rel="noopener noreferrer"><svg class="header-social-icon" width="30" height="30" fill="#000000" viewBox="0 0 32 32"><path fill-rule="evenodd" d="M 16 4 C 9.371094 4 4 9.371094 4 16 C 4 21.300781 7.4375 25.800781 12.207031 27.386719 C 12.808594 27.496094 13.027344 27.128906 13.027344 26.808594 C 13.027344 26.523438 13.015625 25.769531 13.011719 24.769531 C 9.671875 25.492188 8.96875 23.160156 8.96875 23.160156 C 8.421875 21.773438 7.636719 21.402344 7.636719 21.402344 C 6.546875 20.660156 7.71875 20.675781 7.71875 20.675781 C 8.921875 20.761719 9.554688 21.910156 9.554688 21.910156 C 10.625 23.746094 12.363281 23.214844 13.046875 22.910156 C 13.15625 22.132813 13.46875 21.605469 13.808594 21.304688 C 11.144531 21.003906 8.34375 19.972656 8.34375 15.375 C 8.34375 14.0625 8.8125 12.992188 9.578125 12.152344 C 9.457031 11.851563 9.042969 10.628906 9.695313 8.976563 C 9.695313 8.976563 10.703125 8.65625 12.996094 10.207031 C 13.953125 9.941406 14.980469 9.808594 16 9.804688 C 17.019531 9.808594 18.046875 9.941406 19.003906 10.207031 C 21.296875 8.65625 22.300781 8.976563 22.300781 8.976563 C 22.957031 10.628906 22.546875 11.851563 22.421875 12.152344 C 23.191406 12.992188 23.652344 14.0625 23.652344 15.375 C 23.652344 19.984375 20.847656 20.996094 18.175781 21.296875 C 18.605469 21.664063 18.988281 22.398438 18.988281 23.515625 C 18.988281 25.121094 18.976563 26.414063 18.976563 26.808594 C 18.976563 27.128906 19.191406 27.503906 19.800781 27.386719 C 24.566406 25.796875 28 21.300781 28 16 C 28 9.371094 22.628906 4 16 4 Z"></path></svg></a><a class="header-social-link" href="/blog/rss.xml" target="_blank" rel="noopener noreferrer"><svg class="header-social-icon" width="28" height="28" fill="#000000" viewBox="0 0 32 32"><path d="M 5 5 L 5 9 C 14.93 9 23 17.07 23 27 L 27 27 C 27 14.85 17.15 5 5 5 z M 5 12 L 5 16 C 11.07 16 16 20.93 16 27 L 20 27 C 20 18.72 13.28 12 5 12 z M 8 21 A 3 3 0 0 0 8 27 A 3 3 0 0 0 8 21 z"></path></svg></a></div></div><div class="global-content-wrapper" data-is-root-path="false"><main><article class="blog-post" itemscope="" itemType="http://schema.org/Article"><header><h1 itemProp="headline">Building, Breaking, and Tuning - My Experience at the AWS AI League</h1><p class="meta"><span>November 09, 2025</span><span class="meta-separator">•</span><span>11 min read</span></p></header><section itemProp="articleBody" class="blog-content"><p>I promised a lot of folks I’d write a blog if I won the <a href="https://aws.amazon.com/blogs/aws/aws-ai-league-learn-innovate-and-compete-in-our-new-ultimate-ai-showdown/">AWS AI League</a>, so here I am writing this after finishing 2nd.</p>
<p><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; "
    >
      <a
    class="gatsby-resp-image-link"
    href="/blog/static/c50a3cf355fad700579153de9c3dab55/4b319/ai-league-second-place.jpg"
    style="display: block"
    target="_blank"
    rel="noopener"
  >
    <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 66.45569620253164%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAQD/8QAFwEAAwEAAAAAAAAAAAAAAAAAAAECA//aAAwDAQACEAMQAAABnplaVm0M/8QAGhAAAgMBAQAAAAAAAAAAAAAAAAMBAhIRIf/aAAgBAQABBQJK9lkwuOmrHpq5/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFREBAQAAAAAAAAAAAAAAAAAAEBH/2gAIAQIBAT8Bh//EABsQAQACAgMAAAAAAAAAAAAAAAEAMhESAjGR/9oACAEBAAY/AtQMzjvgWdHksyzLs//EABwQAQABBAMAAAAAAAAAAAAAAAEAEBEhcTFBUf/aAAgBAQABPyFm7QTECPMU671axFXK7bxaP//aAAwDAQACAAMAAAAQj9//xAAVEQEBAAAAAAAAAAAAAAAAAAAAEf/aAAgBAwEBPxCI/8QAFxEBAAMAAAAAAAAAAAAAAAAAAAERMf/aAAgBAgEBPxDSof/EAB0QAQACAgIDAAAAAAAAAAAAAAEAESFxMUFhkdH/2gAIAQEAAT8QcROcXHefENQwvBsVjO5YWvXgI4xVu1bIGDIqPe3FLbNnyf/Z'); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="ai league second place"
        title=""
        src="/blog/static/c50a3cf355fad700579153de9c3dab55/828fb/ai-league-second-place.jpg"
        srcset="/blog/static/c50a3cf355fad700579153de9c3dab55/ff44c/ai-league-second-place.jpg 158w,
/blog/static/c50a3cf355fad700579153de9c3dab55/a6688/ai-league-second-place.jpg 315w,
/blog/static/c50a3cf355fad700579153de9c3dab55/828fb/ai-league-second-place.jpg 630w,
/blog/static/c50a3cf355fad700579153de9c3dab55/0ede0/ai-league-second-place.jpg 945w,
/blog/static/c50a3cf355fad700579153de9c3dab55/3ac88/ai-league-second-place.jpg 1260w,
/blog/static/c50a3cf355fad700579153de9c3dab55/4b319/ai-league-second-place.jpg 5472w"
        sizes="(max-width: 630px) 100vw, 630px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
        decoding="async"
      />
  </a>
    </span></p>
<p>Before we begin, here’s a little brief about the competition itself, it consists of two rounds:</p>
<ol>
<li>You are given 72 hours to fine-tune a Llama 3.2 8B model for the given domain using AWS SageMaker JumpStart. When submitted, the fine-tuned model is evaluated against a base Llama 3.2 70B model, with an LLM as a judge, using a fixed set of 50 undisclosed questions. If your fine-tuned model’s answer is better, you get a point. Participants are ranked based on these points in the leaderboard.</li>
<li>For the second round, the top 5 candidates from the first round are chosen. This time, participants craft a system prompt that their fine-tuned model (from the previous round) uses to answer the question. In this round, answers are evaluated by human judges (40%), an LLM (40%) and the audience (20%). The winner is decided based on these points after 5 questions.</li>
</ol>
<h2>Preparation</h2>
<p>Although I have been working with LLMs for the past couple of years, prior to this event, I had only fine-tuned a model once and that too with help. So, I set out to understand it deeply before the competition and started my prep one week prior.</p>
<p>For starters, this <a href="https://www.youtube.com/watch?v=gZP9N86b248&#x26;list=PLBm5soQMjeJ0-h5Dfp_iUFyjUDDbxM8S4&#x26;index=7">video series by AWS</a> helped me get familiar with sagemaker and model fine-tuning. I also looked at several LLM leagues of the past, stumbled upon a blog from the winner of the <a href="https://medium.com/@andyphuawc/my-secret-sauce-for-the-inaugural-singapore-nationwide-aws-large-language-models-league-llml-983d02e63cb3">Singaporean AI league</a> and the blog from <a href="https://github.com/taswhe/2024-sg-lol-papaoutai">first round winner</a> from the same league. Both these blogs discuss data preparation, hyperparameter tuning, and what worked for them. I noted them all down religiously. For those unfamiliar, hyperparameters are like configuration settings that you can adjust while fine-tuning a model.</p>
<p>While I was familiar with data preparation, I realised that I needed to learn more about hyperparameters-that’s when I stumbled upon this <a href="https://aws.amazon.com/blogs/machine-learning/fine-tune-llama-3-for-text-generation-on-amazon-sagemaker-jumpstart/">blog from AWS</a> which was a good starting point. In addition, the table at the end showing fine-tuning times for each instance-size and configuration pair was the cherry on top.</p>
<p><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; "
    >
      <a
    class="gatsby-resp-image-link"
    href="/blog/static/2c8dd6b54f858807bf08ce6260dbda5e/248b0/hyperparameters.png"
    style="display: block"
    target="_blank"
    rel="noopener"
  >
    <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 101.8987341772152%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAABYlAAAWJQFJUiTwAAACt0lEQVR42m2U6ZLiMAyE5/2fb/7twJBA7gtCuMKh7U+JA1u1VKkkB7vdklr+Mv3KsrSiKKyqKsuyzOq6tq7rrO9799h+v3dr29bX+KZplv9YX69X+wJwt9vZ9/e3RVFk6/Xa4jj2CwDH8jx3n6bpAhYsgJ3PZ6AmwOPx+M9NMOR2GLMmA+xwOPih1+tlz+fT/actgNy8Wq3cww7GSZLYdru1zWbjHqMEj8fDxnF0wP/9HBAWpAsITDIBk2auNEulTvr+/aMEZMMFwzB4hsT3+30CJL0NgADpQJOlVqWJtVVpPZvnA+Fw8DThJra327iwdkAYrElZDJMkdR8aAVssnVnDmPigmt/Pg+xs4+lk18v1nfLQH6zcxtYVmW/sxKxRQ4q8sIPY75vaWgHlskap91qPArqJ5W0Q02Mvlrc3IIeS9cpTbQVEurlsJyZ863XJIBYnGemeT2cxO9n9cpnYnQZP/Q3YtZbHkRXJTkBTenSa2tZcICMO4ic+dpOcyKKVzO7q/gLY1ZXtJOhckknVHMCwqfOSkiSDnJAO34kTecozqjHPmd0CiJBjQHQYgwnfYAAj4sAsrPnvRA0FdhEoHV+6zKbf31/bwTCdGH0KGqZ4dErso4lOtTdSXIkAU0TaUw21QCKlNjGCMHRRzyMXrJrrGeJG3c7QrOIwRV/hteFm9Ae7yOtFCZKF3SfTtixc2KOkAtBF3X58NqUVq61qCMtWDdrLOhjADD3O41fN8Wddw9OHLaPXqdjRz49VvIVMi+qXiA1iL8UISeVz9/3xmLseaR8xdYcM4p5mWSnEP38s1YYsnh6J6cVRx7V5PzPgECnXYkWN+YZ0SB/Rv3WolyPNch+tAjmoSRdGSze6zbIIa2qG8Y2HFTD8IhvqgUyQTjy/Oi6jWdykBOvwVvoUeWPeTxeeLv8FcxbnZBXdnS4AAAAASUVORK5CYII='); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="hyperparameters"
        title=""
        src="/blog/static/2c8dd6b54f858807bf08ce6260dbda5e/f058b/hyperparameters.png"
        srcset="/blog/static/2c8dd6b54f858807bf08ce6260dbda5e/c26ae/hyperparameters.png 158w,
/blog/static/2c8dd6b54f858807bf08ce6260dbda5e/6bdcf/hyperparameters.png 315w,
/blog/static/2c8dd6b54f858807bf08ce6260dbda5e/f058b/hyperparameters.png 630w,
/blog/static/2c8dd6b54f858807bf08ce6260dbda5e/40601/hyperparameters.png 945w,
/blog/static/2c8dd6b54f858807bf08ce6260dbda5e/78612/hyperparameters.png 1260w,
/blog/static/2c8dd6b54f858807bf08ce6260dbda5e/248b0/hyperparameters.png 1316w"
        sizes="(max-width: 630px) 100vw, 630px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
        decoding="async"
      />
  </a>
    </span></p>
<p>Plus, reading about these hyperparameters experiments from <a href="https://lightning.ai/pages/community/lora-insights/">Finetuning LLMs with LoRA and QLoRA: Insights from Hundreds of Experiments</a> and <a href="https://magazine.sebastianraschka.com/p/practical-tips-for-finetuning-llms">Practical Tips for Finetuning LLMs Using LoRA</a> made me realise that these parameters are inherently dependent on the data, what works for one set may not necessarily work for another set but it also gave me an idea on what parameters to experiment with.</p>
<p>The crux of what I learnt from these articles,</p>
<ul>
<li>Even 1000 high quality examples is good enough to fine-tune a model</li>
<li>An <code class="language-text">epoch</code> is a hyperparameter representing one complete pass through the entire training dataset during the model training process. So, the plan was to increase epoch slowly from 1 to see which yeilds the best result.</li>
<li><code class="language-text">lora_r</code> (rank) ranges from 4 to 256, with 8, 16, and 32 being common choices (determines the number of trainable parameters in the adaptation layers - high value meaning longer training time and more adaptability)</li>
<li><code class="language-text">lora_alpha</code> is a scaling factor that controls the magnitude of the LoRA weight updates, controls impact of adaptations and is generally kept 2x of lora_r (though above blog also notes successes with 0.5x of lora_r)</li>
<li>Setting lora_r or number of epoch too high can lead to overfitting</li>
<li><code class="language-text">learning_rate</code> rate at which model weights are updated after working through each batch of training examples (regret not experimenting with learning rate in this competition)</li>
<li>Finally, enabling LoRA for more layers i.e. setting target_modules hyperparameter to <code class="language-text">q_proj, v_proj, k_proj, o_proj, gate_proj, up_proj, down_proj</code> instead of the default <code class="language-text">q_proj, v_proj</code>. This proved very effective and almost doubled my score. This video from <a href="https://www.youtube.com/watch?v=eMlx5fFNoYc">3Blue1Brown</a> will help you understand why. You can find more of these in my <a href="https://github.com/nobodyme/aws-ai-league/blob/main/resources.md">raw notes over here</a></li>
</ul>
<p>Then, since, I had time, I thought why not automate some of these like,</p>
<ol>
<li>Deploying the base model</li>
<li>Uploading dataset to s3</li>
<li>Deploying the fine-tuned models with the given array of hyperparameters (so I didn’t have to experiment one by one)</li>
<li>Evaluation against the base model or a previously fine-tuned model to check for regressions (I thought this will be faster than submitting to the leaderboard)</li>
</ol>
<p>I even wrote scripts to increase service-quota limits for the required instances, if not already present. You can <a href="https://github.com/nobodyme/aws-ai-league/tree/main/jumpstart">find them all here</a>.
By doing these, I thought I’ll just concentrate on preparing a good dataset on the event day.</p>
<p><strong>SPOILER ALERT</strong>: None of these were useful in the competition, since we weren’t given access to a Jupyter Notebook or an AWS access key and secret key for the account. So everything had to be done manually through the AWS console.</p>
<p>Talking about data prepation, both these blogs discuss generating data through <a href="https://partyrock.aws/">PartyRock</a>. A few PartyRock apps listed below,</p>
<ul>
<li><a href="https://partyrock.aws/u/papaoutai/ovCF-g4rS/QnACrafter/">QnACrafter</a> - Used by the round 1 winner for the singaporean league</li>
<li><a href="https://partyrock.aws/u/TheRayG/PmL1RViBp/Simple-AWS-LLMs-League-Dataset-Generator">Simple-AWS-LLMs-League-Dataset-Generator</a></li>
<li><a href="https://partyrock.aws/u/TheRayG/IInyME_vt/Advanced-AWS-LLMs-League-Dataset-Generator">Advanced-AWS-LLMs-League-Dataset-Generator</a> both by AWS</li>
<li><a href="https://partyrock.aws/u/JiaweiLin/IvPiedcHN/LLMs-Datasets-Generator">LLMs-Datasets-Generator</a></li>
</ul>
<p>I tried QnACrafter and even modified it slightly to <a href="https://partyrock.aws/u/nobodymenav/hZpzbBFCU/QnACrafter2025-SLED">suit my usecase</a> for the event.</p>
<p>But what if synthetic data generation doesn’t work?
Then I’d have to look at actual sources on the internet-but data can be in different formats like PDF, webpages or CSV</p>
<p>So, I looked for tools that allow us to scrape data from any available source format with minimal effort which is when I landed on <a href="https://github.com/meta-llama/synthetic-data-kit">synthetic-data-kit</a> from Meta, which seems to be built exactly for this purpose, a CLI app that one can run locally to produce questions-answer pairs with PDF, csv or html as the source. It also checks for duplicates and evaluates whether each generated pair is high quality. Seemed like a perfect fit. It internally uses LLM behind the scenes to generate these datasets and allows prompt customization as well. One limitation was the lack of direct Azure OpenAI model support, since I had access to that, I added that support and built a thin wrapper to automate further; you can find the <a href="https://github.com/nobodyme/aws-ai-league/tree/main/data-preparation/synthetic-data-kit">source code here</a>.</p>
<p>At this point, I was clear on how to prepare data and which hyperparameters to experiment with, and all set for the competition.</p>
<h2>Round 1 - Fine-Tuning</h2>
<p>The exact usecase to fine-tune our model was revealed on competition day, although we had already been told that the overall domain as “SLED” (State, Local and Education)</p>
<p><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; "
    >
      <a
    class="gatsby-resp-image-link"
    href="/blog/static/657997a9962d718c550e3b0b51fe316d/1ffbd/domain.png"
    style="display: block"
    target="_blank"
    rel="noopener"
  >
    <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 55.69620253164557%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAACwUlEQVR42l2TyWsTURzHc/Rf8CBuBw96UIS6oBSRongUi1tVFPGgoHhQ677rQfAgQgUPWlesaJHW4lptJolJ02SKNqbLJM1kstgkpkv2TCYf3wzVgz/4Mu/3m/e+7/fe9/tshmEQjUZRVZV4PE5MwPwmEgmKxSJmmHOqVZ2aXsOo1aiL3KgZ/8ZW1OvWf1tNFL99c+F0OpHsdiRJwuNx0/u516onBXmmnKdT/c7b5BjPlSDtwWFeaxpdqQzdmWkeBTReaDl64gVBaNSZKZaZzhcsZGYKpKaLVi2VnaJUqpI2inwoh3gwOkh75Cfd5STPMzHuhcK03HrK9iuPOS9r3PBEsJV0A69Ppq9PwuVyY5ecfLWLbh0u3J5+RkdCTFPkiaOXpv2XudnxhvexAD1JhbsOJ0s3HGHHuTbuBUZo/zGKrVKrM5FKzd5bkqS4u0RMs8bZyUkKuTzDmsq2o60sXLmddVuPs7nlFKfvtLHz8EWWrN9LQ/NJ1u48TcuJ29gMvcLvbJpUeoJMJi0IVZKaYuWJZFyIUcTu8DG/YS8LVu1jwZrdLFqzR3R2gGUbW1jcsIu5y/cwZ94mGrYcFYRigSz7hRhOIYxLHNtlCSNJDvrsEup4mO9KnOYbdjad+Ujj2Xc0tvbQdOkrm69/Yt2xV6w+1MGKg89ovvzO7LDM2MgQP4cGCfyQUcaCwkZhNBNqiMnML/KFGUH6i/7BMP1yCHk4TkDLMyTgD2cZjEwiqzkC6hQ23fRhLIoSVlDGQyiRsAVVizKuRkhnf5smo8vXx7X2+5y4epEH7y+QndJm7Vfnb5h+FaLo+PwyXu+AUNWDd2CAAa8Xv9+P2+0hGBwRdHUkn4dHnZ08fNlB15cX5HLZWZK6RWryWoRVXRe7TZEvlQSE/woFcuKFmMgLlKpVDHNBtYJRKWPoIq/o1sv4P0zCPzpY6bkKhGv/AAAAAElFTkSuQmCC'); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="domain"
        title=""
        src="/blog/static/657997a9962d718c550e3b0b51fe316d/f058b/domain.png"
        srcset="/blog/static/657997a9962d718c550e3b0b51fe316d/c26ae/domain.png 158w,
/blog/static/657997a9962d718c550e3b0b51fe316d/6bdcf/domain.png 315w,
/blog/static/657997a9962d718c550e3b0b51fe316d/f058b/domain.png 630w,
/blog/static/657997a9962d718c550e3b0b51fe316d/40601/domain.png 945w,
/blog/static/657997a9962d718c550e3b0b51fe316d/78612/domain.png 1260w,
/blog/static/657997a9962d718c550e3b0b51fe316d/1ffbd/domain.png 2108w"
        sizes="(max-width: 630px) 100vw, 630px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
        decoding="async"
      />
  </a>
    </span></p>
<p>I honestly did not know what SLED encompassed. So, I set out to find it.
First I tried my modified, <a href="https://partyrock.aws/u/nobodymenav/hZpzbBFCU/QnACrafter2025-SLED">QnACrafter app</a>. It auto selects different aspects when a topic is given (one can also manually specify aspects) and prepares question and answers for it, that gave me a hint but I wanted to dig deeper. Using a combination of generated aspects from PartyRock and a bit of googling, I wrote a few-shot prompt for ChatGPT to give me more SLED topics (the exact prompt below)</p>
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">US State government, Local and Education - understand citizen needs in plain language. 
Handle complex scenarios like "I want to open a food truck" or "My neighbor's tree fell on my property" while providing step-by-step guidance through permit applications and licensing.
Datasets generated should include realistic user queries and appropriate concise and helpful answer like an assistant from US gov public services

I am building a dataset that will help US citizens in navigation government bureaucracy
What all aspects should I cover, I have a few, listed below.

Business Licensing &amp; Permits, Property Rights &amp; Disputes, Education Services, Public Services &amp; Utilities, Public Health, 
Public Transport, 311 requests, building permits, health and food inspection, business registration, property and assessment, 
public works and ROW permits, trees and neighbour hood issues, fire inspection and permits, benefits and human services, 
education, transportation and DMV, Courts &amp; clerks, Community legal aid guide, Street use / right‑of‑way, 
Food vending &amp; food truck, Stormwater &amp; drainage

I want you to think about all such aspects a citizen will reach out to State and local government officals, just like I have written,

Categorize them, example,
1. Business
- (topic related to business why they would reach out, like) business licensing
- business permits

And so on, for all possible things one would likely reach out</code></pre></div>
<p>It responded with the topic and subtopics below, exactly what I was looking for,</p>
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text"> 1. Business &amp; Commerce
 - Business formation (LLC/DBA, Secretary of State filings)
 - General business license / local tax receipt
 - Industry licenses (food service, salon, contractor, childcare, auto dealer)
 ...

 2. Building, Construction &amp; Permitting
 - Building/alteration permits; plan review
 - Mechanical/electrical/plumbing permits
 - Occupancy and fire safety certificates
 ...</code></pre></div>
<p>The full set of generated topics can be <a href="https://github.com/nobodyme/aws-ai-league/blob/main/data-preparation/generate-data-gpt/topics.py">found here</a>. I generated roughly 140 topics. The idea was to feed in these topics to QnACrafter and copy the generated answers but by default it only accepts 4 aspects/topics at a time. Customizing the app to accept more resulted in partial generation, likely due to rate limiting. So, I quickly realized this is going to be time consuming and that it would be easier to write a python script instead to generate the dataset. So that’s what I did, you can <a href="https://github.com/nobodyme/aws-ai-league/tree/main/data-preparation/generate-data-gpt">find the script here</a>.</p>
<p>The script uses <strong>gpt-4o</strong> and takes in a list of topics, and generates N number of questions for each topic. Each question is then passed onto another answer prompt which generates the answer. This produced <a href="https://github.com/nobodyme/aws-ai-league/blob/main/data/first-dataset.jsonl">my first dataset</a>, roughly 870 odd question-answer pairs.</p>
<p>After the competition, many asked how I handled dataset de-duplication. I actually didn’t need a separate de-duplication step, since my approach naturally avoided it. I generated only a handful of questions per topic (about six), and a separate LLM call to generate an answer per question, there was little to no overlap.</p>
<p>Then, I uploaded the dataset with the base hyperparameter configuration. By this time, 5 hours had already passed, I haven’t even looked at the leaderboard yet. The model scored just <strong>31.8%</strong>, but already put me second in the leaderboard at that time. I then, decided to perform all the hyperparameter experiments that I learnt about before discarding the dataset.</p>
<ul>
<li>I started by increasing <strong>epochs</strong> from 1 to 5. The evaluation percentage increased and started to decrease at 5 so I maintained the <strong>epoch at 4</strong>.</li>
<li>Enabling LoRA modules for all layers (instead of just query and key) gave me the biggest jump: <strong>86%</strong> at epoch 3 and <strong>88%</strong> at <strong>epoch 4</strong> with <strong>lora_r=8</strong> and <strong>lora_alpha=16</strong></li>
</ul>
<p>So, the same dataset that got me 31% also fetched me 88% just by tuning the parameters, in other words my fine-tuned LLM is already answering 44/50 questions better than the 70B model.</p>
<p><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; "
    >
      <a
    class="gatsby-resp-image-link"
    href="/blog/static/f5a7eb1d9c55072b9e7e5d25dc8c45a5/57dc1/tuning-scores.png"
    style="display: block"
    target="_blank"
    rel="noopener"
  >
    <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 72.15189873417721%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAABYlAAAWJQFJUiTwAAADZ0lEQVR42mWU+U+URxzG398KmCb9Q/q39IgNoiCxrXIsu8tRSjiWZQ+oUaG1hmOpyLFyrRxFl6sUMBGhpSqsuyAIArsCyyFHQZq1LOXT786maZNO8uTzzkzyzHfmmXe07pEnuEcnmF/dZfPwhLX9d6z//qfS6m7of3q9EyK4H8L7OsTjZwt4pp7y9ugPTk9POTk5Qbs96KTqfi11PzXhcN+hfvgujl7hkJPBl0P0+gbomxmkb/Zf9b8YpHt6AP/WPuLEX6JgMMja2hqaoe4zUio/Ir32U0V93VlSqz8hrfpjCrqSMfd/gcl9iaIH/9Xn5PcksnmwSqQdh4/x+/0sLCygZTUkoauJx1h3Hl11PIYfElQ/qyGRbGcSuW0XKfzxSywDaZT0pVLSH5W5L4Wtg6AyPDw8ZHZ2lrm5ObTSe5kU303D1q5XtLRlKJZ1GLG7DJQ067g5lM/tX63UTlhwiGrGzdSOW9k72lKGodCRVDdHILCCZmrL5esGA4Ut2eQ1GilqzSGvIcqICpqzKHUXUD5i5fqQWbHioY2KURu7RzvRLR+fyvntieEmWmVfIhVdZ/n+wTm+VYxXrOy/wC13Ajfvn5OxBDUfYf2jy7RN6XBOpkiFj8VuhY3NR8zMdPFSQtQ8M+8z8Vss0944xifjeDody4TQ9yIOz0wsU95Ynvti8fhieC797b0Y3oVjOArFyDU5Qzh8Bq/3Azye95if/xCtoucS37Sf57oketV1QXhRmEh5TzI3upO51pmE42EqzidZNE4aRQalO7/o2Hk7JhUu4Q8MiaFLtj2GZm7PIb9Jj6ktU9Hcnh2lK1vJ1JqJtTOXMnc+9p48yofN3Bor5cZIMduH0VDWg9uS8jIrK+toNknT1CzpujIwSbrm1nTVt3Ua1JilPQNrh4HilnSsLj3XenP4bjifyjGThLKpDJeWFvH5vCwvL6HZO7IolqthlStibtERWeAfRmSR61TalUlRUyr2TplrzaCsJ5vqcYuE8kb+FDFclur8AYIbkrK9SwxbdVjuGRRLpAqTVGPvjmzVqMZL5VtVKAtYpX+19yuqxkuihtL8gQALi69YfCUV2hr1FFZfwVKfLryMuS6Nopor2OQcI2PWBp2S3amnrNmIY7QYx4iZqp+LeHOwoQzD4bB6GCKPw99MHTs80wvcGwAAAABJRU5ErkJggg=='); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="tuning scores"
        title=""
        src="/blog/static/f5a7eb1d9c55072b9e7e5d25dc8c45a5/f058b/tuning-scores.png"
        srcset="/blog/static/f5a7eb1d9c55072b9e7e5d25dc8c45a5/c26ae/tuning-scores.png 158w,
/blog/static/f5a7eb1d9c55072b9e7e5d25dc8c45a5/6bdcf/tuning-scores.png 315w,
/blog/static/f5a7eb1d9c55072b9e7e5d25dc8c45a5/f058b/tuning-scores.png 630w,
/blog/static/f5a7eb1d9c55072b9e7e5d25dc8c45a5/57dc1/tuning-scores.png 718w"
        sizes="(max-width: 630px) 100vw, 630px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
        decoding="async"
      />
  </a>
    </span></p>
<p>Here’s the link to the <a href="https://github.com/nobodyme/aws-ai-league/blob/main/data/Finetune.xlsx">full experimentation sheet</a>.</p>
<p>Another key challenge was the limited compute availability — we had access to only two ml.g5.2xlarge and one ml.g5.12xlarge instances for fine-tuning. Several of my hyperparameter configurations failed to run on the smaller instances, which meant I had to rely solely on the single 12xlarge node. This required pacing and prioritizing experiments carefully to make the most of the available resources.</p>
<p>After this, I tried a lot of variations with the dataset.</p>
<ul>
<li>If you observe my previous dataset was generic but we know laws can be different from state to state, so I generated locality-specific data. This fetched me just <strong>15%</strong> with my best hyperparameter configuration. I understood that the evaluation is not locality specific and discarded it entirely.</li>
<li>Then, I wondered if the rest of those 6 questions were in Spanish, since the U.S. has a sizable Spanish-speaking population and appended few spanish datasets for each topic. This also did not improve my score.</li>
<li>Generated and appended summary-based question-answer pairs. Once again, I observed that it performed worse.</li>
<li>Generated more topics with ChatGPT and used the same script to prepare more question/answer pairs for those topics. This improved my score and took me to <strong>90%</strong></li>
<li>Any further topic generation also did not improve the scoreboard.</li>
<li>I also tried switching from gpt4o to 5-mini for generating the dataset, although the questions generated by 5-mini were even more realistic for the same prompt, the score still dropped, suggesting that the evaluation set had simpler question similar to what 4o generated.</li>
<li>Then, my <strong>highest score</strong> came from simply appending refusal type datasets. By refusal I mean, refusing to answer anything irrelevant or aiding harmful intent like giving away personal information of a neighbour etc. This got me upto <strong>94%</strong>. You can find my <a href="https://github.com/nobodyme/aws-ai-league/blob/main/data/final-dataset.jsonl">final dataset here</a>.</li>
<li>Since this got me upto 94%, I did not use the synthetic-data-kit that I had previously tweaked</li>
</ul>
<p>By this time, I was out of ideas to experiment with datasets but I continued experimenting with various other exotic hyperparameter configurations.</p>
<p>One configuration with <strong>lora_r=256</strong> and <strong>lora alpha=128</strong> pushed the score further, yielding just <strong>0.001%</strong> more than my current best model but later looking at the eval/train loss metric on jumpstart I realised this model was overfitting. You can find the comparison of the parameters below.</p>
<p><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; "
    >
      <a
    class="gatsby-resp-image-link"
    href="/blog/static/f4f9e21037c20da97e72aee68b6eacc2/cc488/perf-metrics.png"
    style="display: block"
    target="_blank"
    rel="noopener"
  >
    <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 18.9873417721519%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAYAAACOXx+WAAAACXBIWXMAABYlAAAWJQFJUiTwAAAApElEQVR42m1QyQqFMBDr/39ZBQ+urWIP4nK3VgRxySMD9fIcCGVIyCRVxhhYa9F1HfI8R9M0OM8T932/uK4LnGEYUBQFyrJE3/eY5xlZlqGua3mXZYFKdCKiEALWdcW2bWLyPM8f9n0XDUOkaSoG1Hvv0bYtpmmCIsFkNInzZRbTxqRVVeE4DtnZiDtbKq01nHMvwXpfIBcxjqN8DRPzGI1Zmz4/c80twobxn0YAAAAASUVORK5CYII='); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="perf metrics"
        title=""
        src="/blog/static/f4f9e21037c20da97e72aee68b6eacc2/f058b/perf-metrics.png"
        srcset="/blog/static/f4f9e21037c20da97e72aee68b6eacc2/c26ae/perf-metrics.png 158w,
/blog/static/f4f9e21037c20da97e72aee68b6eacc2/6bdcf/perf-metrics.png 315w,
/blog/static/f4f9e21037c20da97e72aee68b6eacc2/f058b/perf-metrics.png 630w,
/blog/static/f4f9e21037c20da97e72aee68b6eacc2/cc488/perf-metrics.png 928w"
        sizes="(max-width: 630px) 100vw, 630px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
        decoding="async"
      />
  </a>
    </span></p>
<p>A good rule of thumb is to keep eval loss close to training loss, which you can observe in the best model. This means the model generalizes well, otherwise it means the model is overfitting, i.e memorizing training data, such a model won’t fare well with new questions outside training data spec.</p>
<p>I did not check the metrics before submitting, despite knowing that a higher <code class="language-text">lora_r</code> is likely to produce a model that overfits. Unfortunately, I couldn’t beat this model and since AWS copies the model with the highest score for the next round, this ended up being my model for the finals. (Yes, I asked if I could switch the selected model immediately after the Round 1; organizers said they couldn’t)</p>
<p>Anyway, here’s how the leaderboard looked at the end of 72 hours of the first round, where I ended up finishing first.</p>
<p><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; "
    >
      <a
    class="gatsby-resp-image-link"
    href="/blog/static/e1e4d1d6315d0a072463a6a3e5aa5ed5/0e288/leaderboard.png"
    style="display: block"
    target="_blank"
    rel="noopener"
  >
    <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 54.43037974683544%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAACB0lEQVR42nVR227TQBTMnyNxqQQS0I/ggcsjok2bXp5A0IciQVNoiBLROLHjy3p9W6+9aw9nTyxRVbDy2KvdOXPOjEezXwtsghBiu0ZnG+xWP+BfazjXIez8NeziLWydQBmgtT1Gt1GFNx89vL+McXSV4+CbZIy/Zzi7UTif1TgbcPKzxsThRmMyJc7nKY6+XDP/3VeFTwuN0Y+gxd5hjKfHAs8mKfbPMrw4zfi7f57h5anE8xNJZxJ7Y4GHBwKPDh1SPD5WjCdjiQcfBF5d5Bh1XQeVhahUCdWaO1bdtyV0/3d/N4jOwJoGI2s7lErDGIuGBJVuoeoG3ibAbE75+ltq1iBKJGIhkRUV8/NC0V5ByBypLJFmJXRr3YQ9DIUZxgnKsoJSNQQV+r6PKI6RJAKOU1UKNQk5TiozZFmBOBbMdzDGMG/U04tM4WI6owkEdS7w+3aF1cqDlJIEE7ZkrUXf99BaD01TrDyPnbVty3f07DI0tLm8nlFnyRN46w02G5+n225DKjAMF09da55WpBLbMELTtHxmu0GwJ0FyjKv5Elme82UYRfCDAFEUIwzDYQpnyQnWKIoSOXEjismda92g6+8JLvyIJ3SizrLnrdmWEzdkd5dRx5arinJMU3biBJum+WuZM6TNcrHkrs6O7wdYEzngKSOy07GoK3LFLkNJP8bFcT/DPxfCPgn4ay/XAAAAAElFTkSuQmCC'); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="leaderboard"
        title=""
        src="/blog/static/e1e4d1d6315d0a072463a6a3e5aa5ed5/f058b/leaderboard.png"
        srcset="/blog/static/e1e4d1d6315d0a072463a6a3e5aa5ed5/c26ae/leaderboard.png 158w,
/blog/static/e1e4d1d6315d0a072463a6a3e5aa5ed5/6bdcf/leaderboard.png 315w,
/blog/static/e1e4d1d6315d0a072463a6a3e5aa5ed5/f058b/leaderboard.png 630w,
/blog/static/e1e4d1d6315d0a072463a6a3e5aa5ed5/40601/leaderboard.png 945w,
/blog/static/e1e4d1d6315d0a072463a6a3e5aa5ed5/78612/leaderboard.png 1260w,
/blog/static/e1e4d1d6315d0a072463a6a3e5aa5ed5/0e288/leaderboard.png 3018w"
        sizes="(max-width: 630px) 100vw, 630px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
        decoding="async"
      />
  </a>
    </span></p>
<h2>Final Round - Prompt Engineering</h2>
<p>Based on the leaderboard, top 5 candidates along with their fine-tuned model from the previous round are put to test infront of the audience, with human and LLM judges. I had the opportunity to witness AI league final round for another domain in the morning, where I observed humans preferring shorter, succinct answers (at least that’s what I thought). So, I planned to prepare a prompt that gives concise answers too.</p>
<p>Participants were given access to the site where the questions appear, had the ability to tweak the <strong>system prompt</strong> that goes into the model, <strong>temperature</strong> and <strong>top_p</strong>. We had about 60 seconds for each question and were allowed to generate answers multiple times and submit our best one. The prompt I used is pasted below,</p>
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">You are a knowledgeable, efficient, and direct AI assistant that helps US residents navigate public services reducing friction.
Utilize multi-step reasoning to provide concise answers, focusing on key current information in plain language and short sentences. Avoid jargon; if you must use a legal term, define it.
If multiple questions are asked, split them up and address in order that yields the most logical and accurate response.
Offer suggestion tacfully when appropriate to improve outcomes.
Engage in productive collaboration with the user</code></pre></div>
<p>While the LLMs favoured the answer by my model, humans did not and that reflected heavily on the scoreboard. The general consensus from the audience after the show was that my LLM didn’t empathize with the user which is why they did not favour it. Looking at my training data (which already empathizes with the user) and final round output, I suspect I botched this by forcing the prompt to make responses too concise and direct. Nevertheless, I was pretty happy to finish in the second place and loved the overall experience with the league itself. I love debugging in general and I viewed this AI league as a gamified version of debugging a black box (evaluator LLM) and I really played it like a game from day one with all my little experiements.</p>
<p><figure class="gatsby-resp-image-figure" style="">
    <span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; "
    >
      <a
    class="gatsby-resp-image-link"
    href="/blog/static/aa03104dc8b678fca018981e3b40f7b9/6976b/finalists.png"
    style="display: block"
    target="_blank"
    rel="noopener"
  >
    <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 67.72151898734178%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAABYlAAAWJQFJUiTwAAAD/0lEQVR42hWTW1DUBRjF96WHLqZCo9AOAUIgl+UmC3FZLrIry8Ii7oJx2V0tLiIIKELLXWVFYYVFWAXNC5JQYKQkYiikIm0ag6WNlD01EmNiY3hpxhSdX/8evqcz8805Z35HtENxjS3SVgyBpZSGdHH70hOm7z/ij/nn9B+/zn7TGViY45+fp+HlHOaqYWyNwzy8dJ35ke+4ZZ6iNv0CluLTVGkGEK2LrCdTbqEgpZnisHamRmeZuPMXN2ce0/f5j5hrBnj14h4L/z4SHj/AXDfGzZYhnp+/wsuRq/y6b4yWnAmGWkep1fYgSlfUsiF0E+aMMYpkLQx0XeTOzDxdbafo655id+lpepuO8njuLvCU5p3fMmkdg7MTfFPWxkBRDw3ZE9RrrTSnnULUsb2PGuV29DIzeQlGeg73c+/hM7pru/ji0FWs1ecZtgzx+P5dFhbmsZYf44d9A7z8epStsZspVTaxa9NFdqR1YdadRTRz+28uf3aD5qI+qgwWOvYIgsWGWmEi19BPbuZxzvRO0mD8imtXJtCGbcCSXs73e7pJjWlEG2lFGWQiIeYQG9WXET2YfcFPYw+oyT6MMecIySEfo4hrwLBxkJiYTuJiO9hbf4XooDrayk6icMiiJKICTWQVsasPEic9SqjPbnLSBsmInkL07OkrbF/+JsTdiXXXCHpVMeqEehr3TBERakIW1khD5SjBPkVUJLVQJ7NycH0Pcp9t6DPb0SWdIELQdMn9aCJsiFr33mKrrovNa+uwVAxSqjeTmnyA1THtJMg7UcZayRFiSyUlVCj2UubbQlPiMT6Jr8TJoYD1ISai3A0Ee7RgUIwgUqvOIQvvxmQ8xPSNR0yOz6KWV7LkrUghfg7Za6rwdSvjfZcMCqLyyXespEyyi6L4fKHzE/TXj5Ot3Clg10u17gKi+Lj9yOUnyMsxccv2hGuXZpCsUGG3SIrDYmf8Vmjxdy9G7CAj2D6Yzc6VRC9V4u8RxPkjvzDe+yfpyjz0cR2U/A92mLSckGATKrme4ZO/c67/BuJ3vFj8pjdLF4nxdNaw0tWAeHk4Ertwst4tRPyaM77uUViMZ+got/FRyjY0QtcGwZjIz6cQf0k1EcGpdJpsfNp6jmWLXbB/W8KyJU54u6SwyqsQTxctnnYhaJbnIn5djMQ9lvaq05gLBQbzDxAfUMn6yIOCQz8dEs88AlaqqNnSiTHXgv0by3G0cyPMw41VnuvwcdXznmM0TovcSLLPYo2rBC8nf3SJ1RgSTBSkNeLvokb7QQkiqbuMmAAdUd6JxEqSSY3MI3BFHBLX1QIOKoI81AS6fyhcMlK3JCJc0oj3zSRJmKsmyogicAuqkBLCV2Yh98vmP6c6kiNUF0T6AAAAAElFTkSuQmCC'); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="&lt;center style=&quot;margin-top:8px;color:#808086&quot;&gt;Photo with the finalists and judges&lt;center&gt;"
        title=""
        src="/blog/static/aa03104dc8b678fca018981e3b40f7b9/f058b/finalists.png"
        srcset="/blog/static/aa03104dc8b678fca018981e3b40f7b9/c26ae/finalists.png 158w,
/blog/static/aa03104dc8b678fca018981e3b40f7b9/6bdcf/finalists.png 315w,
/blog/static/aa03104dc8b678fca018981e3b40f7b9/f058b/finalists.png 630w,
/blog/static/aa03104dc8b678fca018981e3b40f7b9/40601/finalists.png 945w,
/blog/static/aa03104dc8b678fca018981e3b40f7b9/78612/finalists.png 1260w,
/blog/static/aa03104dc8b678fca018981e3b40f7b9/6976b/finalists.png 2172w"
        sizes="(max-width: 630px) 100vw, 630px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
        decoding="async"
      />
  </a>
    </span>
    <figcaption class="gatsby-resp-image-figcaption"><center style="margin-top:8px;color:#808086">Photo with the finalists and judges<center></figcaption>
  </figure></p>
<h2>Learnings</h2>
<p>At the end of the day, you build for humans, so it would have been wiser to choose the training data aligned to human preference rather than just judging by the LLM evaluation score. If I were to do it again, I’d probably have a vote with non-participants and choose the one they like best. I realised even the response format played a big role. Some of my datasets had answers beginning with <code class="language-text">### ANSWER</code> or <code class="language-text">### RESPONSE</code> and that reflected in the type of outputs it produced as well. To anyone taking this up again, look for these small things to have an edge in the final round, all top 5 participants are probably going to have the facts right for a given question, so how you differentiate your answer to better align with human preference is going to be the key.</p>
<p>Signing up for prompt engineering classes with <a href="https://www.linkedin.com/in/priyadharsini-m-v/">Priyadharsini</a> who became our winner.</p>
<p>Looking at the bigger picture, I learnt a lot about fine-tuning in less than 2 weeks, excited to see where I can put these skills to use in real projects.</p></section></article><nav class="blog-post-nav"><hr class="hr"/><ul style="display:flex;flex-wrap:wrap;justify-content:space-between;list-style:none;padding:0"><li><a rel="prev" href="/blog/lyric-video-generation-using-ai/">← <!-- -->Lyric Video Generation using AI</a></li><li><a rel="next" href="/blog/building-percentage-rollouts/">Building Reliable Percentage Rollouts In-House<!-- --> →</a></li></ul><hr class="hr"/></nav><div class="comment-container"><h4>Comments</h4><p>Want to share feedback, or discuss further ideas? Feel free to leave a comment here! This comment thread directly maps to a <a href="https://github.com/nobodyme/blog/discussions/categories/post-comments">discussion on GitHub</a>, so you can also comment there if you prefer.</p><div class="giscus"></div></div></main></div></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-RTEDBEVJXZ"></script><script>
      
      
      if(true) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-RTEDBEVJXZ', {"send_page_view":false});
      }
      </script><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/aws-ai-league/";/*]]>*/</script><!-- slice-start id="_gatsby-scripts-1" -->
          <script
            id="gatsby-chunk-mapping"
          >
            window.___chunkMapping="{\"app\":[\"/app-c4bce70f7057a2f05845.js\"],\"component---src-pages-404-js\":[\"/component---src-pages-404-js-71e183793d79a34f290b.js\"],\"component---src-pages-index-js\":[\"/component---src-pages-index-js-ee8b5e9d52186f0bdab4.js\"],\"component---src-pages-liked-posts-index-js\":[\"/component---src-pages-liked-posts-index-js-5dfa3066ed0b85ddb4fe.js\"],\"component---src-templates-blog-post-js\":[\"/component---src-templates-blog-post-js-3a99bec1ebda935ca4f5.js\"]}";
          </script>
        <script>window.___webpackCompilationHash="b0e415fca4d96ecaa85a";</script><script src="/blog/webpack-runtime-7db2dcbee5c30cc7fe92.js" async></script><script src="/blog/framework-b99a6c3fa1691c37485a.js" async></script><script src="/blog/app-c4bce70f7057a2f05845.js" async></script><!-- slice-end id="_gatsby-scripts-1" --></body></html>